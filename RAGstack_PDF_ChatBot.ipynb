{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GeorgeCrossIV/RAGstack-PDF-ChatBot/blob/main/RAGstack_PDF_ChatBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ee0e82f-95fa-4efa-84e3-9873d4dcdaf1",
      "metadata": {
        "id": "8ee0e82f-95fa-4efa-84e3-9873d4dcdaf1"
      },
      "source": [
        "# Getting Started with this notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58bc1d2f-7039-4d2a-950c-ff3686013c55",
      "metadata": {
        "id": "58bc1d2f-7039-4d2a-950c-ff3686013c55"
      },
      "source": [
        "- Create a new vector search enabled database in Astra. [astra.datastax.com](https://astra.datastax.com)\n",
        "- For the easy path, name the keyspace in that database \"vector_preview\" (otherwise be prepared to modify the CQL in this notebook)\n",
        "- Create a token with permissions to create tables\n",
        "- Download your secure-connect-bundle zip file.\n",
        "- Download the [sample data file from here](https://drive.google.com/file/d/1KlXnYy6CECoQz7wjf-728ci_unpMSxvF/view?usp=sharing)\n",
        "- When you open this notebook in Google Colab or your own notebook server, drag-and-drop the secure connect bundle and ProductDataset.csv into the File Browser of the notebook\n",
        "- Set up an open.ai API account and generate a key\n",
        "- Update the Keys & Environment Variables cell in the notebook with information from the token you generated and the name of your secure connect bundle file."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c1f964d-aa85-4b2f-a04c-71c295fe9d1e",
      "metadata": {
        "id": "2c1f964d-aa85-4b2f-a04c-71c295fe9d1e"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e57b18c-275c-40bf-8a71-bbb0c94b2a7b",
      "metadata": {
        "scrolled": true,
        "id": "3e57b18c-275c-40bf-8a71-bbb0c94b2a7b"
      },
      "outputs": [],
      "source": [
        "!pip install openai pandas jupyter-datatables cassandra-driver ragstack-ai pypdf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25d08ec4-0e7b-4819-933f-43ed5ff95e48",
      "metadata": {
        "id": "25d08ec4-0e7b-4819-933f-43ed5ff95e48"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "01da99af-da9b-4f38-b841-d802ff23bf2f",
      "metadata": {
        "id": "01da99af-da9b-4f38-b841-d802ff23bf2f"
      },
      "outputs": [],
      "source": [
        "from cassandra.cluster import Cluster\n",
        "from cassandra.auth import PlainTextAuthProvider\n",
        "from cassandra.query import dict_factory\n",
        "from cassandra.query import SimpleStatement\n",
        "from google.colab import userdata\n",
        "import openai\n",
        "import numpy\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7a93b64-e9e9-41d1-95c9-dc9194a5ec8d",
      "metadata": {
        "id": "b7a93b64-e9e9-41d1-95c9-dc9194a5ec8d"
      },
      "source": [
        "# Keys & Environment Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ebeb1df7-2dcc-4ba6-a941-49c68631bd49",
      "metadata": {
        "id": "ebeb1df7-2dcc-4ba6-a941-49c68631bd49"
      },
      "outputs": [],
      "source": [
        "# keys and tokens here\n",
        "openai_api_key = userdata.get('openai_api_key')\n",
        "openai.api_key = openai_api_key\n",
        "cass_user = userdata.get('cass_user')\n",
        "cass_pw = userdata.get('cass_pw')\n",
        "scb_path = '/content/secure-connect-cassio-db.zip'\n",
        "keyspace=\"chatbot\"\n",
        "table=\"chat_documents\"\n",
        "create_embeddings=False"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a96369f4-d311-44c2-8469-f960a2a8718a",
      "metadata": {
        "id": "a96369f4-d311-44c2-8469-f960a2a8718a"
      },
      "source": [
        "# Select a model to compute embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "553fece5-8154-4e18-9610-ff4999bfe171",
      "metadata": {
        "id": "553fece5-8154-4e18-9610-ff4999bfe171"
      },
      "outputs": [],
      "source": [
        "model_id = \"text-embedding-ada-002\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bafd4fc1-84a4-4384-bb3e-42ecffab2455",
      "metadata": {
        "id": "bafd4fc1-84a4-4384-bb3e-42ecffab2455"
      },
      "source": [
        "# Connect to the Cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8c5b0058-391d-421e-81a0-eb2f7fe684df",
      "metadata": {
        "id": "8c5b0058-391d-421e-81a0-eb2f7fe684df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec867d6e-d26e-4a86-bcac-53cad65f1e6d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<cassandra.cluster.Session at 0x7a1e29da0370>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "cloud_config= {\n",
        "  'secure_connect_bundle': scb_path\n",
        "}\n",
        "auth_provider = PlainTextAuthProvider(cass_user, cass_pw)\n",
        "cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider, protocol_version=4)\n",
        "session = cluster.connect()\n",
        "session.set_keyspace(keyspace)\n",
        "session"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0670b30f-927f-47da-b71d-0a99092c3f58",
      "metadata": {
        "id": "0670b30f-927f-47da-b71d-0a99092c3f58"
      },
      "source": [
        "# Drop / Create Schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "acf0fd4c-8367-4d5f-983f-5aa7d14a8948",
      "metadata": {
        "id": "acf0fd4c-8367-4d5f-983f-5aa7d14a8948"
      },
      "outputs": [],
      "source": [
        "# only use this to reset the schema\n",
        "if create_embeddings:\n",
        "  session.execute(f\"\"\"DROP INDEX IF EXISTS {keyspace}.openai_desc\"\"\")\n",
        "  session.execute(f\"\"\"DROP TABLE IF EXISTS {keyspace}.{table}\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a941c487-1c6b-4f46-a0a3-305a95931d82",
      "metadata": {
        "id": "a941c487-1c6b-4f46-a0a3-305a95931d82"
      },
      "outputs": [],
      "source": [
        "if create_embeddings:\n",
        "  # # Create Table\n",
        "  session.execute(f\"\"\"\n",
        "  CREATE TABLE {keyspace}.{table} (\n",
        "      document_id text,\n",
        "      chunk_id int,\n",
        "      document_text text,\n",
        "      embedding_vector vector<float, 1536>,\n",
        "      metadata_blob text,\n",
        "      PRIMARY KEY (document_id, chunk_id))\n",
        "  \"\"\")\n",
        "\n",
        "  # # Create Index\n",
        "  session.execute(f\"\"\"\n",
        "  CREATE CUSTOM INDEX IF NOT EXISTS openai_desc ON {keyspace}.{table} (embedding_vector)\n",
        "  USING 'org.apache.cassandra.index.sai.StorageAttachedIndex'\n",
        "  \"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load PDF"
      ],
      "metadata": {
        "id": "k0oaemdk4n-4"
      },
      "id": "k0oaemdk4n-4"
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://github.com/GeorgeCrossIV/CassIO---PDF-Law-case-questions/raw/main/McCall-v-Microsoft.pdf\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOBbDMpe4p0u",
        "outputId": "d587d2fc-13f6-4a65-96f7-d5e03f1075b5"
      },
      "id": "zOBbDMpe4p0u",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-08 06:07:04--  https://github.com/GeorgeCrossIV/CassIO---PDF-Law-case-questions/raw/main/McCall-v-Microsoft.pdf\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/GeorgeCrossIV/CassIO---PDF-Law-case-questions/main/McCall-v-Microsoft.pdf [following]\n",
            "--2023-12-08 06:07:04--  https://raw.githubusercontent.com/GeorgeCrossIV/CassIO---PDF-Law-case-questions/main/McCall-v-Microsoft.pdf\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 254969 (249K) [application/octet-stream]\n",
            "Saving to: ‘McCall-v-Microsoft.pdf.1’\n",
            "\n",
            "McCall-v-Microsoft. 100%[===================>] 248.99K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2023-12-08 06:07:04 (5.70 MB/s) - ‘McCall-v-Microsoft.pdf.1’ saved [254969/254969]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader('McCall-v-Microsoft.pdf')\n",
        "pages = loader.load_and_split()\n",
        "#pages[2]\n"
      ],
      "metadata": {
        "id": "hr3kc8i14rHe"
      },
      "id": "hr3kc8i14rHe",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "c1fe256f-9efb-41f0-8803-d99696c6089b",
      "metadata": {
        "id": "c1fe256f-9efb-41f0-8803-d99696c6089b"
      },
      "source": [
        "# Load the table with data and create text embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "14eb4355-9fcd-4795-8406-aee98fd4b11f",
      "metadata": {
        "scrolled": true,
        "id": "14eb4355-9fcd-4795-8406-aee98fd4b11f"
      },
      "outputs": [],
      "source": [
        "if create_embeddings:\n",
        "  document_chunk_id = 0\n",
        "  for page in pages:\n",
        "    # Create Embedding for each conversation row, save them to the database\n",
        "    text_chunk_length = 400\n",
        "    text_chunks = [page.page_content[i:i + text_chunk_length] for i in range(0, len(page.page_content), text_chunk_length)]\n",
        "    for chunk_id, chunk in enumerate(text_chunks):\n",
        "      document_chunk_id += 1\n",
        "      metadata_blob=f\"Page: {page.metadata['page']}\"\n",
        "      embedding = openai.embeddings.create(input=chunk, model=model_id).data[0].embedding\n",
        "      query = SimpleStatement(\n",
        "                  f\"\"\"\n",
        "                  INSERT INTO {keyspace}.{table}\n",
        "                  (document_id, chunk_id, document_text, embedding_vector, metadata_blob)\n",
        "                  VALUES (%s, %s, %s, %s, %s)\n",
        "                  \"\"\"\n",
        "              )\n",
        "    session.execute(query, (page.metadata['source'], document_chunk_id, chunk, embedding, metadata_blob ))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fc20311-5fde-46b1-b194-4611866f4264",
      "metadata": {
        "id": "2fc20311-5fde-46b1-b194-4611866f4264"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Start using the index"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83f833ef-6555-452b-a903-9505c77b75b1",
      "metadata": {
        "id": "83f833ef-6555-452b-a903-9505c77b75b1"
      },
      "source": [
        "In the steps up to this point, we have been creating a schema and loading the table with data, including embeddings we generated through the OpenAI Embedding API.\n",
        "Now we are going to query that table and use the results to give ChatGPT some context to support it's response."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "466ca4e3-7bb6-485b-ac3a-788c1fe3658d",
      "metadata": {
        "id": "466ca4e3-7bb6-485b-ac3a-788c1fe3658d"
      },
      "source": [
        "# Convert a query string into a text embedding to use as part of the query"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37217051-b389-49eb-8b5b-6efb14d9f8c4",
      "metadata": {
        "id": "37217051-b389-49eb-8b5b-6efb14d9f8c4"
      },
      "source": [
        "This is where the real fun starts.  Provide a question or request to be used as the query.  The source sample database is mostly consumer electronics and appliances, so imagine you're talking to a customer service rep at Best Buy or another electronics store.\n",
        "\n",
        "Here we use the same API that we used to calculate embeddings for each row in the database, but this time we are using your input question to calculate a vector to use in a query."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1036a24f-d527-410b-b73c-d2e191b792a5",
      "metadata": {
        "id": "1036a24f-d527-410b-b73c-d2e191b792a5"
      },
      "source": [
        "Let's take a look at what a query against a vector index could look like.  The query vector has the same dimensions (number of entries in the list) as the embeddings we generated a few steps ago for each row in the database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "ed786879-c639-458c-84e4-b657b2fba9a1",
      "metadata": {
        "scrolled": true,
        "id": "ed786879-c639-458c-84e4-b657b2fba9a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90a2a3c2-f4f2-42ce-a91a-c007bac37cb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.protocol:Server warning: Top-K queries can only be run with consistency level ONE / LOCAL_ONE / NODE_LOCAL. Consistency level LOCAL_QUORUM was requested. Downgrading the consistency level to LOCAL_ONE.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The McCall v. Microsoft Corp. case involves a dispute between McCall, the plaintiff, and Microsoft Corporation, the defendant. The case was filed in the United States District Court for the Southern District of New York. The background details of the case are not provided in the document.\n"
          ]
        }
      ],
      "source": [
        "customer_input = \"What is the background of the McCall v. Microsoft Corp. case?\"\n",
        "\n",
        "embedding = openai.embeddings.create(input=customer_input, model=model_id).data[0].embedding\n",
        "\n",
        "query = SimpleStatement(\n",
        "    f\"\"\"\n",
        "    SELECT *\n",
        "    FROM {keyspace}.{table}\n",
        "    ORDER BY embedding_vector ANN OF {embedding} LIMIT 5;\n",
        "    \"\"\"\n",
        "    )\n",
        "#display(query)\n",
        "results = session.execute(query)\n",
        "top_5_products = results._current_rows\n",
        "\n",
        "#for row in top_5_products:\n",
        "#  print(f\"\"\"{row.document_id}, {row.document_text}, {row.metadata_blob}\\n\"\"\")\n",
        "\n",
        "message_objects = []\n",
        "message_objects.append({\"role\":\"system\",\n",
        "                        \"content\":\"You're a chatbot answering questions about a document\"})\n",
        "\n",
        "message_objects.append({\"role\":\"user\",\n",
        "                        \"content\": customer_input})\n",
        "\n",
        "products_list = []\n",
        "\n",
        "for row in top_5_products:\n",
        "    brand_dict = {'role': \"assistant\", \"content\": f\"{row.document_text}\"}\n",
        "    products_list.append(brand_dict)\n",
        "\n",
        "message_objects.extend(products_list)\n",
        "message_objects.append({\"role\": \"assistant\", \"content\":\"Here's my summarized answer:\"})\n",
        "\n",
        "completion = openai.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=message_objects\n",
        ")\n",
        "print(completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "customer_input = \"Who are the defendents in the case?\"\n",
        "\n",
        "embedding = openai.embeddings.create(input=customer_input, model=model_id).data[0].embedding\n",
        "\n",
        "query = SimpleStatement(\n",
        "    f\"\"\"\n",
        "    SELECT *\n",
        "    FROM {keyspace}.{table}\n",
        "    ORDER BY embedding_vector ANN OF {embedding} LIMIT 10;\n",
        "    \"\"\"\n",
        "    )\n",
        "\n",
        "message_objects = []\n",
        "message_objects.append({\"role\":\"system\",\n",
        "                        \"content\":\"You're a chatbot answering questions about a document\"})\n",
        "\n",
        "message_objects.append({\"role\":\"user\",\n",
        "                        \"content\": customer_input})\n",
        "\n",
        "products_list = []\n",
        "\n",
        "for row in top_5_products:\n",
        "    brand_dict = {'role': \"assistant\", \"content\": f\"{row.document_text}\"}\n",
        "    products_list.append(brand_dict)\n",
        "\n",
        "message_objects.extend(products_list)\n",
        "message_objects.append({\"role\": \"assistant\", \"content\":\"Here's my summarized answer:\"})\n",
        "\n",
        "completion = openai.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=message_objects\n",
        ")\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paRq9JKWXqPH",
        "outputId": "aa38c117-2ffa-403f-cb2c-dc7414094d68"
      },
      "id": "paRq9JKWXqPH",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The defendants in the case are tiff WA, Berman Beerman, Steve W. Hagens Lovell, Christopher Lovell and P.S., Stewart PH/MDL, Seattle, WA, Richard C. LLP, New City, Giovanniello, York Earle II, Pepperman, Cromwell, Sullivan & PH/ PC, Enright Haven, CT, Gorman and MDL, New New York City, for Microsoft Corporation.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}